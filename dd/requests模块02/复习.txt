1. 数据来源
	公司自行产生
	购买
	免费获取
	人工获取
	爬虫

2. 模拟浏览器发送请求获取响应

3. 爬虫流程
	a. url
	b. 发送请求获取响应
	c. 提取数据，处理保存
	d. 提取new_url，重复b步骤

4. http(s)复习
	# 超本文 传输 协议 + ssl安全 套接字 层

	# 浏览器最终展示的结果是由多次请求对应的多次响应共同渲染出来的

	# user-agent referer cookie
	# set-cookie

	# 200 3xx 4xx 5xx

5. str.encode() / bytes.decode(utf8)
	# gbk gb2312 ascii iso-88959-1

6. requests简单发送get请求
	response = requests.get(url)

7. response常用属性
	response.url
	response.status_code
	response.headers # 响应头 dict
	response.request.headers
	response.cookies # cookiejar
	response.request._cookies 

8. response内容
	response.text # str, 利用chardet模块推测
	response.content # bytes
	# response.content.decode()

9. 获取的图片音频视频文件要以bytes类型保存！

